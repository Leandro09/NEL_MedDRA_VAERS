{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import ast\n",
    "from spacy.ml.models import load_kb\n",
    "import random  \n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0792f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activar gpu\n",
    "activated = spacy.prefer_gpu()\n",
    "spacy.require_gpu()\n",
    "\n",
    "#cargar modelo\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e50459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar dataset que sirve de entrenamiento\n",
    "dataframeNEL = pd.read_csv(\"train_dataset.csv\",encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombrar columnas\n",
    "dataframeNEL = dataframeNEL.set_axis(['Reports', 'Labels'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar duplicados\n",
    "dataframeNEL = dataframeNEL.drop_duplicates('Reports')\n",
    "len(dataframeNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08100aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener primeros 3000 registros\n",
    "dataframeNEL = dataframeNEL.head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear diccionario para enviar al proceso de entrenamiento\n",
    "dataset = []\n",
    "for index, row in dataframeNEL.iterrows():\n",
    "    dataset.append((row[\"Reports\"],ast.literal_eval(row[\"Labels\"])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b67b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear objeto para hacer division entre conjunto de entrenamiento y pruebas\n",
    "xs = []\n",
    "ys = []            \n",
    "\n",
    "for index, (text, annot) in enumerate(dataset):\n",
    "\n",
    "  y = []\n",
    "\n",
    "  subLinks = []\n",
    "  for span, links_dict in annot[\"links\"].items():\n",
    "    \n",
    "          \n",
    "    for link, value in links_dict.items():\n",
    "      \n",
    "      link = int(link)\n",
    "      if link in name_dict.keys() and value:\n",
    "        subLinks.append(link)\n",
    "    \n",
    "  y.append(subLinks)\n",
    "  if len(y) != 0:\n",
    "    xs.append(dataset[index])  \n",
    "    ys.append(y[0])   \n",
    "\n",
    "\n",
    "train_dataset, test_dataset, y_train, y_test = train_test_split(xs,ys,test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "print (f\"Number of sentences. Total: {len(dataset)}. Number of training sentences: {len(train_dataset)}. Number of test sentences: {len(test_dataset)}\")\n",
    "print (*[f\"Test sentence: text -> '{text}'\\t annotation -> {annot}\" for text, annot in test_dataset], sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb53815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear objeto example que se requier enviar a entity linker\n",
    "TRAIN_EXAMPLES = []\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "  nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "sentencizer = nlp.get_pipe(\"sentencizer\")\n",
    "for text, annotation in train_dataset:\n",
    "  print(text)\n",
    "  example = Example.from_dict(nlp.make_doc(text), annotation)\n",
    "  example.reference = sentencizer(example.reference)\n",
    "  TRAIN_EXAMPLES.append(example)\n",
    "print (\"'train_dataset' has been transformed to 'train_examples', a dataset with spaCy 'example' objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar entity linker a pipeline\n",
    "entity_linker = nlp.add_pipe(\"entity_linker\", config={\"incl_prior\": False}, last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbacf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicializar entity linker con objeto Example\n",
    "entity_linker.initialize(get_examples=lambda: TRAIN_EXAMPLES, kb_loader=load_kb(\"nel_kb_v3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamiento de entity linker, en caso de querer entrenar entidades, colocar ner en la lista de enable\n",
    "with nlp.select_pipes(enable=[\"entity_linker\"]): \n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(1000):   \n",
    "        random.shuffle(TRAIN_EXAMPLES)\n",
    "        batches = minibatch(TRAIN_EXAMPLES, size=compounding(4.0, 32.0, 1.001))  # increasing batch sizes\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            nlp.update(\n",
    "                batch,   \n",
    "                drop=0.2,      \n",
    "                losses=losses,\n",
    "                sgd=optimizer,\n",
    "            )\n",
    "        if itn % 50 == 0:\n",
    "            print(itn, \"Losses\", losses)   # print the training loss\n",
    "print(itn, \"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"NEL_Model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de predicci√≥n\n",
    "text = \"very sick; horrible; has allergy to environmental items like dust/grass; sinuses were irritating; they were \\\"hoping tomorrow [they would be] back to [their] real normal; headache; stomach ache; fever; aches; diarrhea; booster; whole body hurts; breaking out on their face/looked like redness has spread slightly beyond bite area (no threat); had rash developing in cracks of lips that was told to me yesterday; This is a spontaneous report received from a contactable reporter(s) (Consumer or other non HCP).  A 54 year-old female patient (not pregnant) received bnt162b2 (BNT162B2), administration date 10Dec2021 (Batch/Lot number: unknown) at the age of 54 years as dose 3 (booster), single for covid-19 immunisation. Relevant medical history included: \\\"history anxiety/depression\\\" (unspecified if ongoing); \\\"history anxiety/depression\\\" (unspecified if ongoing); \\\"high blood pressure\\\" (unspecified if ongoing); \\\"cosmetic related surgery earlier this year\\\", start date: 2021 (unspecified if ongoing), notes: other medical history: cosmetic related surgery earlier this year; \\\"scoliosis with implanted spinal rod and associated back/neck pain\\\" (unspecified if ongoing); \\\"scoliosis with implanted spinal rod and associated back/neck pain\\\" (unspecified if ongoing); \\\"scoliosis with implanted spinal rod and associated back/neck pain\\\" (unspecified if ongoing); \\\"Reaction : Allergy\\\" (unspecified if ongoing); \\\"Covid\\\" (unspecified if ongoing), notes: did have Covid at some point before being vaccinated. The patient took concomitant medications. Vaccination history included: Bnt162b2 (Dose Number: 2, Batch/Lot No: Unknown. Not available/provided to reporter at the time of report completion, prev dose administration date: 10Jun2021), administration date: 10Jun2021, when the patient was 54 years old, for COVID-19 immunisation; Bnt162b2 (Dose Number: 1, Batch/Lot No: Unknown., prev dose administration date: 20May2021), administration date: 20May2021, when the patient was 54 years old, for COVID-19 immunisation. The following information was reported: IMMUNISATION (non-serious) with onset 10Dec2021, outcome \\\"unknown\\\", described as \\\"booster\\\"; PAIN (non-serious) with onset 10Dec2021, outcome \\\"not recovered\\\", described as \\\"whole body hurts\\\"; HEADACHE (non-serious) with onset 12Dec2021, outcome \\\"not recovered\\\", described as \\\"headache\\\"; PYREXIA (non-serious) with onset 10Dec2021, outcome \\\"not recovered\\\", described as \\\"fever\\\"; PAIN (non-serious) with onset 10Dec2021, outcome \\\"not recovered\\\", described as \\\"aches\\\"; DIARRHOEA (non-serious) with onset 10Dec2021, outcome \\\"not recovered\\\", described as \\\"diarrhea\\\"; ABDOMINAL PAIN UPPER (non-serious) with onset 12Dec2021, outcome \\\"unknown\\\", described as \\\"stomach ache\\\"; FEELING ABNORMAL (non-serious) with onset 12Dec2021 20:21, outcome \\\"unknown\\\", described as \\\"they were \\\"hoping tomorrow [they would be] back to [their] real normal\\\"; ERYTHEMA (non-serious) with onset Dec2021, outcome \\\"unknown\\\", described as \\\"breaking out on their face/looked like redness has spread slightly beyond bite area (no threat)\\\"; ILLNESS (non-serious), outcome \\\"unknown\\\", described as \\\"very sick\\\"; MALAISE (non-serious), outcome \\\"unknown\\\", described as \\\"horrible\\\"; HYPERSENSITIVITY (non-serious), outcome \\\"unknown\\\", described as \\\"has allergy to environmental items like dust/grass\\\"; SINUS DISORDER (non-serious) with onset 24Dec2021, outcome \\\"unknown\\\", described as \\\"sinuses were irritating\\\"; RASH (non-serious) with onset Dec2021, outcome \\\"unknown\\\", described as \\\"had rash developing in cracks of lips that was told to me yesterday\\\". Relevant laboratory tests and procedures are available in the appropriate section.  Follow-up (11Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a 54-year-old female patient that:  Updated information included : Historical vaccine, Relevant medical history, New event of \\\"stomach ache\\\".  Follow-up (12Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a patient that:  Updated information included : New event of \\\"they were \\\"hoping tomorrow [they would be] back to [their] real normal\\\".  Follow-up (17Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported in response to non-HCP letter sent via Email follow-up activity that included:  Updated information included : Reporter's Phone number  Follow-up (20Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported in response to non-HCP letter sent via Email follow-up activity that included:  Updated information included: Historical vaccine start and stop date.  Follow-up (20Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported in response to non-HCP letter sent via Email follow-up activity that included:  Additional information : Sorry third email but one more detail - there are many other reports submitted previously that this one can be linked to. All with same patient initials and DOB thank you,  Follow-up (20Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a patient that:  Updated information included: Relevant Medical History.  Follow-up (20Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a patient that:  Updated information included: New event of \\\"very sick, horrible\\\".  Follow-up (25Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a patient that:  Follow-up (24Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported in response to non-HCP letter sent via Email follow-up activity that included:  Updated information included : New event of  \\\"has allergy to environmental items like dust/grass\\\"  Follow-up (24Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported in response to non-HCP letter sent via Email follow-up activity that included:  Follow-up (25Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a patient that:  Updated information included : Lab test, New event of \\\"sinuses were irritating\\\".  Follow-up (24Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported in response to non-HCP letter sent via Email follow-up activity that included:  Follow-up (26Dec2021): This is a spontaneous follow-up report from same contactable consumer. This consumer reported for a patient that:  Updated information included : Lab test, New event of \\\"had rash developing in cracks of lips that was told to me yesterday\\\".  The lot number for bnt162b2 was not provided and will be requested during follow up.\"\n",
    "doc = nlpTest(text)\n",
    "for ent in doc.ents:\n",
    "  print(f\"Mention: {ent.text}. Entity type: {ent.label_}. Entity ID: {ent.kb_id_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d95317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar predicciones para el conjunto de pruevas\n",
    "\n",
    "field_names=[\"text\",\"Gold annotation\",\"ent_text\",\"ent_labels\",\"annotations\"]\n",
    "    \n",
    "with open('testDataset.csv', 'a', newline='', encoding=\"utf-8\") as f_object:\n",
    "      \n",
    "\n",
    "    dictwriter_object = DictWriter(f_object, fieldnames=field_names)\n",
    "        \n",
    "    for text, true_annot in test_dataset:\n",
    "            \n",
    "        entitiesText = []\n",
    "        entitiesLabels = []\n",
    "        annoTest = []\n",
    "            \n",
    "             \n",
    "        doc = nlp(text)  # to make this more efficient, you can use nlp.pipe() just once for all the texts\n",
    "        for ent in doc.ents:\n",
    "            entitiesText.append(ent.text)\n",
    "            entitiesLabels.append(ent.label_)\n",
    "            annoTest.append(ent.kb_id_)\n",
    "        dictwriter_object.writerow({\"text\":text,\"Gold annotation\":true_annot,\"ent_text\":entitiesText,\"ent_labels\":entitiesLabels, \"annotations\":annoTest}) \n",
    "\n",
    "          \n",
    "\n",
    "#Close the file object\n",
    "f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear arreglo docs con predicciones en el conjunto de pruebas\n",
    "docs = []\n",
    "for text, true_annot in test_dataset:\n",
    "        doc = nlp(text)\n",
    "        docs.append(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir documento para poder hacer etiquetado\n",
    "from spacy.tokens import DocBin\n",
    "doc_bin = DocBin(docs=docs)\n",
    "doc_bin.to_disk(\"testData.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra de etiqueda con modelo\n",
    "from spacy.tokens import DocBin\n",
    "import random\n",
    "doc_bin = DocBin().from_disk(\"testData.spacy\")\n",
    "\n",
    "docs = list(doc_bin.get_docs(nlpTest.vocab))\n",
    "\n",
    "\n",
    "for i, doc in enumerate(random.sample(docs,5)):\n",
    "  print(f\"\\n## Sentence {i+1}:\")\n",
    "  spacy.displacy.render(doc, style=\"ent\", jupyter=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear objeto con datos de conjunto de prueba\n",
    "dataset = []\n",
    "for index, row in testData.iterrows():\n",
    "    dataset.append((row[\"Reports\"],ast.literal_eval(row[\"Gold_annotation\"])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417efe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []        \n",
    "\n",
    "# crear objeto para poder evaluar calidad en el conjunto de prueba\n",
    "for index, (text, annot) in enumerate(dataset):\n",
    "\n",
    "  y = []\n",
    "\n",
    "  subLinks = []\n",
    "  for span, links_dict in annot[\"links\"].items():\n",
    "    \n",
    "          \n",
    "    for link, value in links_dict.items():\n",
    "      \n",
    "      link = int(link)\n",
    "      if link in name_dict.keys() and value:\n",
    "        subLinks.append(link)\n",
    "    \n",
    "  y.append(subLinks)\n",
    "  if len(y) != 0:\n",
    "    xs.append(dataset[index])  \n",
    "    ys.append(y[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d51bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluaci√≥n de calidad en conjunto de prueba\n",
    "examples = []\n",
    "data = xs\n",
    "for text, annots in data:\n",
    "    doc = nlpTest.make_doc(text)\n",
    "    examples.append(Example.from_dict(doc, annots))\n",
    "print(nlpTest.evaluate(examples)) # This will provide overall and per entity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para elaborar este c√≥digo se utiliza como ejemplo el trabajo realizado por Nadjet Bouayad-Agha y dem√°s colaboradores en https://drive.google.com/drive/folders/1D30X0jUpaGLwsQckNybs6D7-00Nj4SVn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
